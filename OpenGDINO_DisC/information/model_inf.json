
{
    "transformer.level_embed": 1024,
    "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
    "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
    "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
    "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
    "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
    "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
    "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
    "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
    "transformer.encoder.layers.0.norm1.weight": 256,
    "transformer.encoder.layers.0.norm1.bias": 256,
    "transformer.encoder.layers.0.linear1.weight": 524288,
    "transformer.encoder.layers.0.linear1.bias": 2048,
    "transformer.encoder.layers.0.linear2.weight": 524288,
    "transformer.encoder.layers.0.linear2.bias": 256,
    "transformer.encoder.layers.0.norm2.weight": 256,
    "transformer.encoder.layers.0.norm2.bias": 256,
    "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
    "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
    "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
    "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
    "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
    "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
    "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
    "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
    "transformer.encoder.layers.1.norm1.weight": 256,
    "transformer.encoder.layers.1.norm1.bias": 256,
    "transformer.encoder.layers.1.linear1.weight": 524288,
    "transformer.encoder.layers.1.linear1.bias": 2048,
    "transformer.encoder.layers.1.linear2.weight": 524288,
    "transformer.encoder.layers.1.linear2.bias": 256,
    "transformer.encoder.layers.1.norm2.weight": 256,
    "transformer.encoder.layers.1.norm2.bias": 256,
    "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
    "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
    "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
    "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
    "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
    "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
    "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
    "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
    "transformer.encoder.layers.2.norm1.weight": 256,
    "transformer.encoder.layers.2.norm1.bias": 256,
    "transformer.encoder.layers.2.linear1.weight": 524288,
    "transformer.encoder.layers.2.linear1.bias": 2048,
    "transformer.encoder.layers.2.linear2.weight": 524288,
    "transformer.encoder.layers.2.linear2.bias": 256,
    "transformer.encoder.layers.2.norm2.weight": 256,
    "transformer.encoder.layers.2.norm2.bias": 256,
    "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
    "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
    "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
    "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
    "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
    "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
    "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
    "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
    "transformer.encoder.layers.3.norm1.weight": 256,
    "transformer.encoder.layers.3.norm1.bias": 256,
    "transformer.encoder.layers.3.linear1.weight": 524288,
    "transformer.encoder.layers.3.linear1.bias": 2048,
    "transformer.encoder.layers.3.linear2.weight": 524288,
    "transformer.encoder.layers.3.linear2.bias": 256,
    "transformer.encoder.layers.3.norm2.weight": 256,
    "transformer.encoder.layers.3.norm2.bias": 256,
    "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
    "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
    "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
    "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
    "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
    "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
    "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
    "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
    "transformer.encoder.layers.4.norm1.weight": 256,
    "transformer.encoder.layers.4.norm1.bias": 256,
    "transformer.encoder.layers.4.linear1.weight": 524288,
    "transformer.encoder.layers.4.linear1.bias": 2048,
    "transformer.encoder.layers.4.linear2.weight": 524288,
    "transformer.encoder.layers.4.linear2.bias": 256,
    "transformer.encoder.layers.4.norm2.weight": 256,
    "transformer.encoder.layers.4.norm2.bias": 256,
    "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
    "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
    "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
    "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
    "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
    "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
    "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
    "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
    "transformer.encoder.layers.5.norm1.weight": 256,
    "transformer.encoder.layers.5.norm1.bias": 256,
    "transformer.encoder.layers.5.linear1.weight": 524288,
    "transformer.encoder.layers.5.linear1.bias": 2048,
    "transformer.encoder.layers.5.linear2.weight": 524288,
    "transformer.encoder.layers.5.linear2.bias": 256,
    "transformer.encoder.layers.5.norm2.weight": 256,
    "transformer.encoder.layers.5.norm2.bias": 256,
    "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
    "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
    "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
    "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
    "transformer.encoder.text_layers.0.linear1.weight": 262144,
    "transformer.encoder.text_layers.0.linear1.bias": 1024,
    "transformer.encoder.text_layers.0.linear2.weight": 262144,
    "transformer.encoder.text_layers.0.linear2.bias": 256,
    "transformer.encoder.text_layers.0.norm1.weight": 256,
    "transformer.encoder.text_layers.0.norm1.bias": 256,
    "transformer.encoder.text_layers.0.norm2.weight": 256,
    "transformer.encoder.text_layers.0.norm2.bias": 256,
    "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
    "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
    "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
    "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
    "transformer.encoder.text_layers.1.linear1.weight": 262144,
    "transformer.encoder.text_layers.1.linear1.bias": 1024,
    "transformer.encoder.text_layers.1.linear2.weight": 262144,
    "transformer.encoder.text_layers.1.linear2.bias": 256,
    "transformer.encoder.text_layers.1.norm1.weight": 256,
    "transformer.encoder.text_layers.1.norm1.bias": 256,
    "transformer.encoder.text_layers.1.norm2.weight": 256,
    "transformer.encoder.text_layers.1.norm2.bias": 256,
    "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
    "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
    "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
    "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
    "transformer.encoder.text_layers.2.linear1.weight": 262144,
    "transformer.encoder.text_layers.2.linear1.bias": 1024,
    "transformer.encoder.text_layers.2.linear2.weight": 262144,
    "transformer.encoder.text_layers.2.linear2.bias": 256,
    "transformer.encoder.text_layers.2.norm1.weight": 256,
    "transformer.encoder.text_layers.2.norm1.bias": 256,
    "transformer.encoder.text_layers.2.norm2.weight": 256,
    "transformer.encoder.text_layers.2.norm2.bias": 256,
    "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
    "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
    "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
    "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
    "transformer.encoder.text_layers.3.linear1.weight": 262144,
    "transformer.encoder.text_layers.3.linear1.bias": 1024,
    "transformer.encoder.text_layers.3.linear2.weight": 262144,
    "transformer.encoder.text_layers.3.linear2.bias": 256,
    "transformer.encoder.text_layers.3.norm1.weight": 256,
    "transformer.encoder.text_layers.3.norm1.bias": 256,
    "transformer.encoder.text_layers.3.norm2.weight": 256,
    "transformer.encoder.text_layers.3.norm2.bias": 256,
    "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
    "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
    "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
    "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
    "transformer.encoder.text_layers.4.linear1.weight": 262144,
    "transformer.encoder.text_layers.4.linear1.bias": 1024,
    "transformer.encoder.text_layers.4.linear2.weight": 262144,
    "transformer.encoder.text_layers.4.linear2.bias": 256,
    "transformer.encoder.text_layers.4.norm1.weight": 256,
    "transformer.encoder.text_layers.4.norm1.bias": 256,
    "transformer.encoder.text_layers.4.norm2.weight": 256,
    "transformer.encoder.text_layers.4.norm2.bias": 256,
    "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
    "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
    "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
    "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
    "transformer.encoder.text_layers.5.linear1.weight": 262144,
    "transformer.encoder.text_layers.5.linear1.bias": 1024,
    "transformer.encoder.text_layers.5.linear2.weight": 262144,
    "transformer.encoder.text_layers.5.linear2.bias": 256,
    "transformer.encoder.text_layers.5.norm1.weight": 256,
    "transformer.encoder.text_layers.5.norm1.bias": 256,
    "transformer.encoder.text_layers.5.norm2.weight": 256,
    "transformer.encoder.text_layers.5.norm2.bias": 256,
    "transformer.encoder.fusion_layers.0.gamma_v": 256,
    "transformer.encoder.fusion_layers.0.gamma_l": 256,
    "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
    "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
    "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
    "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
    "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
    "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
    "transformer.encoder.fusion_layers.1.gamma_v": 256,
    "transformer.encoder.fusion_layers.1.gamma_l": 256,
    "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
    "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
    "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
    "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
    "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
    "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
    "transformer.encoder.fusion_layers.2.gamma_v": 256,
    "transformer.encoder.fusion_layers.2.gamma_l": 256,
    "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
    "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
    "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
    "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
    "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
    "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
    "transformer.encoder.fusion_layers.3.gamma_v": 256,
    "transformer.encoder.fusion_layers.3.gamma_l": 256,
    "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
    "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
    "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
    "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
    "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
    "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
    "transformer.encoder.fusion_layers.4.gamma_v": 256,
    "transformer.encoder.fusion_layers.4.gamma_l": 256,
    "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
    "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
    "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
    "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
    "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
    "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
    "transformer.encoder.fusion_layers.5.gamma_v": 256,
    "transformer.encoder.fusion_layers.5.gamma_l": 256,
    "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
    "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
    "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
    "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
    "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
    "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
    "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
    "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
    "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
    "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
    "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
    "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
    "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
    "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
    "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
    "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
    "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
    "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
    "transformer.decoder.layers.0.norm1.weight": 256,
    "transformer.decoder.layers.0.norm1.bias": 256,
    "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
    "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
    "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
    "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
    "transformer.decoder.layers.0.catext_norm.weight": 256,
    "transformer.decoder.layers.0.catext_norm.bias": 256,
    "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
    "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
    "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
    "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
    "transformer.decoder.layers.0.norm2.weight": 256,
    "transformer.decoder.layers.0.norm2.bias": 256,
    "transformer.decoder.layers.0.linear1.weight": 524288,
    "transformer.decoder.layers.0.linear1.bias": 2048,
    "transformer.decoder.layers.0.linear2.weight": 524288,
    "transformer.decoder.layers.0.linear2.bias": 256,
    "transformer.decoder.layers.0.norm3.weight": 256,
    "transformer.decoder.layers.0.norm3.bias": 256,
    "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
    "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
    "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
    "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
    "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
    "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
    "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
    "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
    "transformer.decoder.layers.1.norm1.weight": 256,
    "transformer.decoder.layers.1.norm1.bias": 256,
    "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
    "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
    "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
    "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
    "transformer.decoder.layers.1.catext_norm.weight": 256,
    "transformer.decoder.layers.1.catext_norm.bias": 256,
    "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
    "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
    "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
    "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
    "transformer.decoder.layers.1.norm2.weight": 256,
    "transformer.decoder.layers.1.norm2.bias": 256,
    "transformer.decoder.layers.1.linear1.weight": 524288,
    "transformer.decoder.layers.1.linear1.bias": 2048,
    "transformer.decoder.layers.1.linear2.weight": 524288,
    "transformer.decoder.layers.1.linear2.bias": 256,
    "transformer.decoder.layers.1.norm3.weight": 256,
    "transformer.decoder.layers.1.norm3.bias": 256,
    "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
    "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
    "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
    "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
    "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
    "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
    "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
    "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
    "transformer.decoder.layers.2.norm1.weight": 256,
    "transformer.decoder.layers.2.norm1.bias": 256,
    "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
    "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
    "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
    "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
    "transformer.decoder.layers.2.catext_norm.weight": 256,
    "transformer.decoder.layers.2.catext_norm.bias": 256,
    "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
    "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
    "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
    "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
    "transformer.decoder.layers.2.norm2.weight": 256,
    "transformer.decoder.layers.2.norm2.bias": 256,
    "transformer.decoder.layers.2.linear1.weight": 524288,
    "transformer.decoder.layers.2.linear1.bias": 2048,
    "transformer.decoder.layers.2.linear2.weight": 524288,
    "transformer.decoder.layers.2.linear2.bias": 256,
    "transformer.decoder.layers.2.norm3.weight": 256,
    "transformer.decoder.layers.2.norm3.bias": 256,
    "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
    "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
    "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
    "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
    "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
    "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
    "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
    "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
    "transformer.decoder.layers.3.norm1.weight": 256,
    "transformer.decoder.layers.3.norm1.bias": 256,
    "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
    "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
    "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
    "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
    "transformer.decoder.layers.3.catext_norm.weight": 256,
    "transformer.decoder.layers.3.catext_norm.bias": 256,
    "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
    "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
    "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
    "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
    "transformer.decoder.layers.3.norm2.weight": 256,
    "transformer.decoder.layers.3.norm2.bias": 256,
    "transformer.decoder.layers.3.linear1.weight": 524288,
    "transformer.decoder.layers.3.linear1.bias": 2048,
    "transformer.decoder.layers.3.linear2.weight": 524288,
    "transformer.decoder.layers.3.linear2.bias": 256,
    "transformer.decoder.layers.3.norm3.weight": 256,
    "transformer.decoder.layers.3.norm3.bias": 256,
    "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
    "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
    "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
    "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
    "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
    "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
    "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
    "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
    "transformer.decoder.layers.4.norm1.weight": 256,
    "transformer.decoder.layers.4.norm1.bias": 256,
    "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
    "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
    "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
    "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
    "transformer.decoder.layers.4.catext_norm.weight": 256,
    "transformer.decoder.layers.4.catext_norm.bias": 256,
    "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
    "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
    "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
    "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
    "transformer.decoder.layers.4.norm2.weight": 256,
    "transformer.decoder.layers.4.norm2.bias": 256,
    "transformer.decoder.layers.4.linear1.weight": 524288,
    "transformer.decoder.layers.4.linear1.bias": 2048,
    "transformer.decoder.layers.4.linear2.weight": 524288,
    "transformer.decoder.layers.4.linear2.bias": 256,
    "transformer.decoder.layers.4.norm3.weight": 256,
    "transformer.decoder.layers.4.norm3.bias": 256,
    "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
    "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
    "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
    "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
    "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
    "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
    "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
    "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
    "transformer.decoder.layers.5.norm1.weight": 256,
    "transformer.decoder.layers.5.norm1.bias": 256,
    "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
    "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
    "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
    "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
    "transformer.decoder.layers.5.catext_norm.weight": 256,
    "transformer.decoder.layers.5.catext_norm.bias": 256,
    "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
    "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
    "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
    "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
    "transformer.decoder.layers.5.norm2.weight": 256,
    "transformer.decoder.layers.5.norm2.bias": 256,
    "transformer.decoder.layers.5.linear1.weight": 524288,
    "transformer.decoder.layers.5.linear1.bias": 2048,
    "transformer.decoder.layers.5.linear2.weight": 524288,
    "transformer.decoder.layers.5.linear2.bias": 256,
    "transformer.decoder.layers.5.norm3.weight": 256,
    "transformer.decoder.layers.5.norm3.bias": 256,
    "transformer.decoder.norm.weight": 256,
    "transformer.decoder.norm.bias": 256,
    "transformer.decoder.ref_point_head.layers.0.weight": 131072,
    "transformer.decoder.ref_point_head.layers.0.bias": 256,
    "transformer.decoder.ref_point_head.layers.1.weight": 65536,
    "transformer.decoder.ref_point_head.layers.1.bias": 256,
    "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
    "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
    "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
    "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
    "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
    "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
    "transformer.tgt_embed.weight": 230400,
    "transformer.enc_output.weight": 65536,
    "transformer.enc_output.bias": 256,
    "transformer.enc_output_norm.weight": 256,
    "transformer.enc_output_norm.bias": 256,
    "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
    "transformer.enc_out_bbox_embed.layers.0.bias": 256,
    "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
    "transformer.enc_out_bbox_embed.layers.1.bias": 256,
    "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
    "transformer.enc_out_bbox_embed.layers.2.bias": 4,
    "bert.embeddings.word_embeddings.weight": 23440896,
    "bert.embeddings.position_embeddings.weight": 393216,
    "bert.embeddings.token_type_embeddings.weight": 1536,
    "bert.embeddings.LayerNorm.weight": 768,
    "bert.embeddings.LayerNorm.bias": 768,
    "bert.encoder.layer.0.attention.self.query.weight": 589824,
    "bert.encoder.layer.0.attention.self.query.bias": 768,
    "bert.encoder.layer.0.attention.self.key.weight": 589824,
    "bert.encoder.layer.0.attention.self.key.bias": 768,
    "bert.encoder.layer.0.attention.self.value.weight": 589824,
    "bert.encoder.layer.0.attention.self.value.bias": 768,
    "bert.encoder.layer.0.attention.output.dense.weight": 589824,
    "bert.encoder.layer.0.attention.output.dense.bias": 768,
    "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.0.intermediate.dense.bias": 3072,
    "bert.encoder.layer.0.output.dense.weight": 2359296,
    "bert.encoder.layer.0.output.dense.bias": 768,
    "bert.encoder.layer.0.output.LayerNorm.weight": 768,
    "bert.encoder.layer.0.output.LayerNorm.bias": 768,
    "bert.encoder.layer.1.attention.self.query.weight": 589824,
    "bert.encoder.layer.1.attention.self.query.bias": 768,
    "bert.encoder.layer.1.attention.self.key.weight": 589824,
    "bert.encoder.layer.1.attention.self.key.bias": 768,
    "bert.encoder.layer.1.attention.self.value.weight": 589824,
    "bert.encoder.layer.1.attention.self.value.bias": 768,
    "bert.encoder.layer.1.attention.output.dense.weight": 589824,
    "bert.encoder.layer.1.attention.output.dense.bias": 768,
    "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.1.intermediate.dense.bias": 3072,
    "bert.encoder.layer.1.output.dense.weight": 2359296,
    "bert.encoder.layer.1.output.dense.bias": 768,
    "bert.encoder.layer.1.output.LayerNorm.weight": 768,
    "bert.encoder.layer.1.output.LayerNorm.bias": 768,
    "bert.encoder.layer.2.attention.self.query.weight": 589824,
    "bert.encoder.layer.2.attention.self.query.bias": 768,
    "bert.encoder.layer.2.attention.self.key.weight": 589824,
    "bert.encoder.layer.2.attention.self.key.bias": 768,
    "bert.encoder.layer.2.attention.self.value.weight": 589824,
    "bert.encoder.layer.2.attention.self.value.bias": 768,
    "bert.encoder.layer.2.attention.output.dense.weight": 589824,
    "bert.encoder.layer.2.attention.output.dense.bias": 768,
    "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.2.intermediate.dense.bias": 3072,
    "bert.encoder.layer.2.output.dense.weight": 2359296,
    "bert.encoder.layer.2.output.dense.bias": 768,
    "bert.encoder.layer.2.output.LayerNorm.weight": 768,
    "bert.encoder.layer.2.output.LayerNorm.bias": 768,
    "bert.encoder.layer.3.attention.self.query.weight": 589824,
    "bert.encoder.layer.3.attention.self.query.bias": 768,
    "bert.encoder.layer.3.attention.self.key.weight": 589824,
    "bert.encoder.layer.3.attention.self.key.bias": 768,
    "bert.encoder.layer.3.attention.self.value.weight": 589824,
    "bert.encoder.layer.3.attention.self.value.bias": 768,
    "bert.encoder.layer.3.attention.output.dense.weight": 589824,
    "bert.encoder.layer.3.attention.output.dense.bias": 768,
    "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.3.intermediate.dense.bias": 3072,
    "bert.encoder.layer.3.output.dense.weight": 2359296,
    "bert.encoder.layer.3.output.dense.bias": 768,
    "bert.encoder.layer.3.output.LayerNorm.weight": 768,
    "bert.encoder.layer.3.output.LayerNorm.bias": 768,
    "bert.encoder.layer.4.attention.self.query.weight": 589824,
    "bert.encoder.layer.4.attention.self.query.bias": 768,
    "bert.encoder.layer.4.attention.self.key.weight": 589824,
    "bert.encoder.layer.4.attention.self.key.bias": 768,
    "bert.encoder.layer.4.attention.self.value.weight": 589824,
    "bert.encoder.layer.4.attention.self.value.bias": 768,
    "bert.encoder.layer.4.attention.output.dense.weight": 589824,
    "bert.encoder.layer.4.attention.output.dense.bias": 768,
    "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.4.intermediate.dense.bias": 3072,
    "bert.encoder.layer.4.output.dense.weight": 2359296,
    "bert.encoder.layer.4.output.dense.bias": 768,
    "bert.encoder.layer.4.output.LayerNorm.weight": 768,
    "bert.encoder.layer.4.output.LayerNorm.bias": 768,
    "bert.encoder.layer.5.attention.self.query.weight": 589824,
    "bert.encoder.layer.5.attention.self.query.bias": 768,
    "bert.encoder.layer.5.attention.self.key.weight": 589824,
    "bert.encoder.layer.5.attention.self.key.bias": 768,
    "bert.encoder.layer.5.attention.self.value.weight": 589824,
    "bert.encoder.layer.5.attention.self.value.bias": 768,
    "bert.encoder.layer.5.attention.output.dense.weight": 589824,
    "bert.encoder.layer.5.attention.output.dense.bias": 768,
    "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.5.intermediate.dense.bias": 3072,
    "bert.encoder.layer.5.output.dense.weight": 2359296,
    "bert.encoder.layer.5.output.dense.bias": 768,
    "bert.encoder.layer.5.output.LayerNorm.weight": 768,
    "bert.encoder.layer.5.output.LayerNorm.bias": 768,
    "bert.encoder.layer.6.attention.self.query.weight": 589824,
    "bert.encoder.layer.6.attention.self.query.bias": 768,
    "bert.encoder.layer.6.attention.self.key.weight": 589824,
    "bert.encoder.layer.6.attention.self.key.bias": 768,
    "bert.encoder.layer.6.attention.self.value.weight": 589824,
    "bert.encoder.layer.6.attention.self.value.bias": 768,
    "bert.encoder.layer.6.attention.output.dense.weight": 589824,
    "bert.encoder.layer.6.attention.output.dense.bias": 768,
    "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.6.intermediate.dense.bias": 3072,
    "bert.encoder.layer.6.output.dense.weight": 2359296,
    "bert.encoder.layer.6.output.dense.bias": 768,
    "bert.encoder.layer.6.output.LayerNorm.weight": 768,
    "bert.encoder.layer.6.output.LayerNorm.bias": 768,
    "bert.encoder.layer.7.attention.self.query.weight": 589824,
    "bert.encoder.layer.7.attention.self.query.bias": 768,
    "bert.encoder.layer.7.attention.self.key.weight": 589824,
    "bert.encoder.layer.7.attention.self.key.bias": 768,
    "bert.encoder.layer.7.attention.self.value.weight": 589824,
    "bert.encoder.layer.7.attention.self.value.bias": 768,
    "bert.encoder.layer.7.attention.output.dense.weight": 589824,
    "bert.encoder.layer.7.attention.output.dense.bias": 768,
    "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.7.intermediate.dense.bias": 3072,
    "bert.encoder.layer.7.output.dense.weight": 2359296,
    "bert.encoder.layer.7.output.dense.bias": 768,
    "bert.encoder.layer.7.output.LayerNorm.weight": 768,
    "bert.encoder.layer.7.output.LayerNorm.bias": 768,
    "bert.encoder.layer.8.attention.self.query.weight": 589824,
    "bert.encoder.layer.8.attention.self.query.bias": 768,
    "bert.encoder.layer.8.attention.self.key.weight": 589824,
    "bert.encoder.layer.8.attention.self.key.bias": 768,
    "bert.encoder.layer.8.attention.self.value.weight": 589824,
    "bert.encoder.layer.8.attention.self.value.bias": 768,
    "bert.encoder.layer.8.attention.output.dense.weight": 589824,
    "bert.encoder.layer.8.attention.output.dense.bias": 768,
    "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.8.intermediate.dense.bias": 3072,
    "bert.encoder.layer.8.output.dense.weight": 2359296,
    "bert.encoder.layer.8.output.dense.bias": 768,
    "bert.encoder.layer.8.output.LayerNorm.weight": 768,
    "bert.encoder.layer.8.output.LayerNorm.bias": 768,
    "bert.encoder.layer.9.attention.self.query.weight": 589824,
    "bert.encoder.layer.9.attention.self.query.bias": 768,
    "bert.encoder.layer.9.attention.self.key.weight": 589824,
    "bert.encoder.layer.9.attention.self.key.bias": 768,
    "bert.encoder.layer.9.attention.self.value.weight": 589824,
    "bert.encoder.layer.9.attention.self.value.bias": 768,
    "bert.encoder.layer.9.attention.output.dense.weight": 589824,
    "bert.encoder.layer.9.attention.output.dense.bias": 768,
    "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.9.intermediate.dense.bias": 3072,
    "bert.encoder.layer.9.output.dense.weight": 2359296,
    "bert.encoder.layer.9.output.dense.bias": 768,
    "bert.encoder.layer.9.output.LayerNorm.weight": 768,
    "bert.encoder.layer.9.output.LayerNorm.bias": 768,
    "bert.encoder.layer.10.attention.self.query.weight": 589824,
    "bert.encoder.layer.10.attention.self.query.bias": 768,
    "bert.encoder.layer.10.attention.self.key.weight": 589824,
    "bert.encoder.layer.10.attention.self.key.bias": 768,
    "bert.encoder.layer.10.attention.self.value.weight": 589824,
    "bert.encoder.layer.10.attention.self.value.bias": 768,
    "bert.encoder.layer.10.attention.output.dense.weight": 589824,
    "bert.encoder.layer.10.attention.output.dense.bias": 768,
    "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.10.intermediate.dense.bias": 3072,
    "bert.encoder.layer.10.output.dense.weight": 2359296,
    "bert.encoder.layer.10.output.dense.bias": 768,
    "bert.encoder.layer.10.output.LayerNorm.weight": 768,
    "bert.encoder.layer.10.output.LayerNorm.bias": 768,
    "bert.encoder.layer.11.attention.self.query.weight": 589824,
    "bert.encoder.layer.11.attention.self.query.bias": 768,
    "bert.encoder.layer.11.attention.self.key.weight": 589824,
    "bert.encoder.layer.11.attention.self.key.bias": 768,
    "bert.encoder.layer.11.attention.self.value.weight": 589824,
    "bert.encoder.layer.11.attention.self.value.bias": 768,
    "bert.encoder.layer.11.attention.output.dense.weight": 589824,
    "bert.encoder.layer.11.attention.output.dense.bias": 768,
    "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
    "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
    "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
    "bert.encoder.layer.11.intermediate.dense.bias": 3072,
    "bert.encoder.layer.11.output.dense.weight": 2359296,
    "bert.encoder.layer.11.output.dense.bias": 768,
    "bert.encoder.layer.11.output.LayerNorm.weight": 768,
    "bert.encoder.layer.11.output.LayerNorm.bias": 768,
    "feat_map.weight": 196608,
    "feat_map.bias": 256,
    "input_proj.0.0.weight": 49152,
    "input_proj.0.0.bias": 256,
    "input_proj.0.1.weight": 256,
    "input_proj.0.1.bias": 256,
    "input_proj.1.0.weight": 98304,
    "input_proj.1.0.bias": 256,
    "input_proj.1.1.weight": 256,
    "input_proj.1.1.bias": 256,
    "input_proj.2.0.weight": 196608,
    "input_proj.2.0.bias": 256,
    "input_proj.2.1.weight": 256,
    "input_proj.2.1.bias": 256,
    "input_proj.3.0.weight": 1769472,
    "input_proj.3.0.bias": 256,
    "input_proj.3.1.weight": 256,
    "input_proj.3.1.bias": 256,
    "backbone.0.patch_embed.proj.weight": 4608,
    "backbone.0.patch_embed.proj.bias": 96,
    "backbone.0.patch_embed.norm.weight": 96,
    "backbone.0.patch_embed.norm.bias": 96,
    "backbone.0.layers.0.blocks.0.norm1.weight": 96,
    "backbone.0.layers.0.blocks.0.norm1.bias": 96,
    "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
    "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
    "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
    "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
    "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
    "backbone.0.layers.0.blocks.0.norm2.weight": 96,
    "backbone.0.layers.0.blocks.0.norm2.bias": 96,
    "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
    "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
    "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
    "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
    "backbone.0.layers.0.blocks.1.norm1.weight": 96,
    "backbone.0.layers.0.blocks.1.norm1.bias": 96,
    "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
    "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
    "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
    "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
    "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
    "backbone.0.layers.0.blocks.1.norm2.weight": 96,
    "backbone.0.layers.0.blocks.1.norm2.bias": 96,
    "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
    "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
    "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
    "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
    "backbone.0.layers.0.downsample.reduction.weight": 73728,
    "backbone.0.layers.0.downsample.norm.weight": 384,
    "backbone.0.layers.0.downsample.norm.bias": 384,
    "backbone.0.layers.1.blocks.0.norm1.weight": 192,
    "backbone.0.layers.1.blocks.0.norm1.bias": 192,
    "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
    "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
    "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
    "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
    "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
    "backbone.0.layers.1.blocks.0.norm2.weight": 192,
    "backbone.0.layers.1.blocks.0.norm2.bias": 192,
    "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
    "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
    "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
    "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
    "backbone.0.layers.1.blocks.1.norm1.weight": 192,
    "backbone.0.layers.1.blocks.1.norm1.bias": 192,
    "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
    "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
    "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
    "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
    "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
    "backbone.0.layers.1.blocks.1.norm2.weight": 192,
    "backbone.0.layers.1.blocks.1.norm2.bias": 192,
    "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
    "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
    "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
    "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
    "backbone.0.layers.1.downsample.reduction.weight": 294912,
    "backbone.0.layers.1.downsample.norm.weight": 768,
    "backbone.0.layers.1.downsample.norm.bias": 768,
    "backbone.0.layers.2.blocks.0.norm1.weight": 384,
    "backbone.0.layers.2.blocks.0.norm1.bias": 384,
    "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
    "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
    "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
    "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
    "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
    "backbone.0.layers.2.blocks.0.norm2.weight": 384,
    "backbone.0.layers.2.blocks.0.norm2.bias": 384,
    "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
    "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
    "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
    "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
    "backbone.0.layers.2.blocks.1.norm1.weight": 384,
    "backbone.0.layers.2.blocks.1.norm1.bias": 384,
    "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
    "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
    "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
    "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
    "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
    "backbone.0.layers.2.blocks.1.norm2.weight": 384,
    "backbone.0.layers.2.blocks.1.norm2.bias": 384,
    "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
    "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
    "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
    "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
    "backbone.0.layers.2.blocks.2.norm1.weight": 384,
    "backbone.0.layers.2.blocks.2.norm1.bias": 384,
    "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
    "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
    "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
    "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
    "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
    "backbone.0.layers.2.blocks.2.norm2.weight": 384,
    "backbone.0.layers.2.blocks.2.norm2.bias": 384,
    "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
    "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
    "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
    "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
    "backbone.0.layers.2.blocks.3.norm1.weight": 384,
    "backbone.0.layers.2.blocks.3.norm1.bias": 384,
    "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
    "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
    "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
    "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
    "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
    "backbone.0.layers.2.blocks.3.norm2.weight": 384,
    "backbone.0.layers.2.blocks.3.norm2.bias": 384,
    "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
    "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
    "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
    "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
    "backbone.0.layers.2.blocks.4.norm1.weight": 384,
    "backbone.0.layers.2.blocks.4.norm1.bias": 384,
    "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
    "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
    "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
    "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
    "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
    "backbone.0.layers.2.blocks.4.norm2.weight": 384,
    "backbone.0.layers.2.blocks.4.norm2.bias": 384,
    "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
    "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
    "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
    "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
    "backbone.0.layers.2.blocks.5.norm1.weight": 384,
    "backbone.0.layers.2.blocks.5.norm1.bias": 384,
    "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
    "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
    "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
    "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
    "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
    "backbone.0.layers.2.blocks.5.norm2.weight": 384,
    "backbone.0.layers.2.blocks.5.norm2.bias": 384,
    "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
    "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
    "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
    "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
    "backbone.0.layers.2.downsample.reduction.weight": 1179648,
    "backbone.0.layers.2.downsample.norm.weight": 1536,
    "backbone.0.layers.2.downsample.norm.bias": 1536,
    "backbone.0.layers.3.blocks.0.norm1.weight": 768,
    "backbone.0.layers.3.blocks.0.norm1.bias": 768,
    "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
    "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
    "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
    "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
    "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
    "backbone.0.layers.3.blocks.0.norm2.weight": 768,
    "backbone.0.layers.3.blocks.0.norm2.bias": 768,
    "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
    "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
    "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
    "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
    "backbone.0.layers.3.blocks.1.norm1.weight": 768,
    "backbone.0.layers.3.blocks.1.norm1.bias": 768,
    "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
    "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
    "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
    "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
    "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
    "backbone.0.layers.3.blocks.1.norm2.weight": 768,
    "backbone.0.layers.3.blocks.1.norm2.bias": 768,
    "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
    "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
    "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
    "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
    "backbone.0.norm1.weight": 192,
    "backbone.0.norm1.bias": 192,
    "backbone.0.norm2.weight": 384,
    "backbone.0.norm2.bias": 384,
    "backbone.0.norm3.weight": 768,
    "backbone.0.norm3.bias": 768
  }